[{
    "id": "intelligent_rag",
    "user_id": "",
    "name": "Intelligent RAG",
    "type": "pipe",
    "content": "from typing import Optional, Callable, Awaitable\nfrom pydantic import BaseModel, Field\nimport requests\n\nclass Pipe:\n    class Valves(BaseModel):\n        server_url: str = Field(\n            default=\"http://localhost:3000\",\n            description=\"URL of the intelligent-rag-server\"\n        )\n        project_id: str = Field(\n            default=\"default\",\n            description=\"Project ID to query against\"\n        )\n        thinking_depth: int = Field(\n            default=2,\n            description=\"Depth of thinking (1-4)\",\n            ge=1,\n            le=4\n        )\n\n    def __init__(self):\n        self.type = \"pipe\"\n        self.id = \"intelligent_rag\"\n        self.name = \"Intelligent RAG\"\n        self.valves = self.Valves()\n\n    async def pipe(\n        self,\n        body: dict,\n        __user__: Optional[dict] = None,\n        __event_emitter__: Optional[Callable[[dict], Awaitable[None]]] = None,\n        __event_call__: Optional[Callable[[dict], Awaitable[dict]]] = None,\n    ) -> Optional[dict]:\n        messages = body.get(\"messages\", [])\n\n        if messages:\n            question = messages[-1][\"content\"]\n            try:\n                headers = {\"Content-Type\": \"application/json\"}\n                payload = {\n                    \"projectId\": self.valves.project_id,\n                    \"query\": question,\n                    \"thinkingDepth\": self.valves.thinking_depth\n                }\n                response = requests.post(\n                    f\"{self.valves.server_url}/api/query\",\n                    json=payload,\n                    headers=headers\n                )\n                \n                if response.status_code == 200:\n                    rag_response = response.json()\n                    answer = rag_response.get(\"answer\", \"\")\n                    log = rag_response.get(\"log\", \"\")\n                    sources = rag_response.get(\"sources\", [])\n                    \n                    # Add thinking process as system message if available\n                    if log:\n                        thinking_lines = [line.strip() for line in log.split(\"\\n\") if line.strip()]\n                        if thinking_lines:\n                            body[\"messages\"].append({\n                                \"role\": \"system\",\n                                \"content\": \"ðŸ¤” **Thinking Process**\\n\" + \"\\n\".join(f\"- {line}\" for line in thinking_lines)\n                            })\n                    \n                    # Add main answer\n                    body[\"messages\"].append({\n                        \"role\": \"assistant\",\n                        \"content\": answer\n                    })\n                    \n                else:\n                    raise Exception(f\"Error: {response.status_code} - {response.text}\")\n\n            except Exception as e:\n                return {\"error\": str(e)}\n        else:\n            body[\"messages\"].append({\n                \"role\": \"assistant\",\n                \"content\": \"No messages found in the request body\"\n            })\n\n        return answer",
    "meta": {
        "description": "Allows you to chat with an intelligent RAG server that provides enhanced search and reasoning capabilities"
    },
    "manifest": {
        "title": "Intelligent RAG Function",
        "author": "OpenHands",
        "version": "0.1.0"
    },
    "is_active": false,
    "is_global": false,
    "updated_at": 1747598592,
    "created_at": 1747598592
}]